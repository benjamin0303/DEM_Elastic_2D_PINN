{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd277be5736648daacdd43ffb38e9c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Authenticated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting runtime=hpc_gpu...\n",
      "[NCSADelta:gpuA100x4, 60 Minutes, 1 Node(s), 4 CPU(s), 0 GPU(s), 4000 MB RAM, 0 MB VRAM]\n",
      "* modules=[]\n",
      "* libraries=['python=3.10', 'pip', 'make', 'cmake', 'compilers', 'openmpi', 'wget']\n",
      "* pip=[]\n",
      "* mounts=[]\n",
      "Requested runtime=hpc_gpu\n",
      "Request successful: runtime=hpc_gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2fe8ca2082459c9534eab73b5e11f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local:C:/Users/benja/AppData/Local/Temp/connection_px_hyjvb.json --> hpc_gpu:connection_px_hyjvb.json... [200]\n",
      "started proc_name=hpc_gpu_kernel on rt=hpc_gpu. pid=879727\n",
      "forwarding ports=[18215, 18216, 18217, 18218, 18219]\n",
      "hpc_gpu:18215 -> access via 18.118.140.230:10000\n",
      "hpc_gpu:18216 -> access via 18.118.140.230:10001\n",
      "hpc_gpu:18217 -> access via 18.118.140.230:10002\n",
      "hpc_gpu:18218 -> access via 18.118.140.230:10003\n",
      "hpc_gpu:18219 -> access via 18.118.140.230:10004\n",
      "started ipykernel tunnels for hpc_gpu at 18.118.140.230\n",
      "started ipykernel client for hpc_gpu\n",
      "Remote Jupyter kernel launched and connected for runtime=hpc_gpu.\n",
      "Switched to runtime=hpc_gpu.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"airavata-python-sdk[notebook]\"\n",
    "import airavata_jupyter_magic\n",
    "\n",
    "%authenticate\n",
    "\n",
    "# Request resource on SDSC Expanse\n",
    "# %request_runtime hpc_cpu --file=cybershuttle.yml --walltime=60 --use=expanse:shared   # expanse:gpu-shared\n",
    "\n",
    "# Request resource on Jetstream 2\n",
    "#%request_runtime hpc_cpu --file=cybershuttle.yml --walltime=60 --use=NeuroData25VC1:cloud\n",
    "\n",
    "# Request resource on Delta\n",
    "%request_runtime hpc_gpu --file=cybershuttle.yml --walltime=60 --use=NCSADelta:gpuA100x4\n",
    "\n",
    "%wait_for_runtime hpc_gpu --live\n",
    "#%copy_data source=local:case.py target=hpc_cpu:case.py\n",
    "\n",
    "%switch_runtime hpc_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_gpu...\n",
      "waiting for cell to finish on hpc_gpu...\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.1 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch)\n",
      "  Using cached triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from triton==3.3.0->torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /dev/shm/cybershuttle/envs/b7a017a2/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/216.6 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0mInterrupt sent to remote kernel, waiting for response...\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%copy_data` not found.\n"
     ]
    }
   ],
   "source": [
    "#%copy_data source=local:Sub_Functions/IntegrationFext.py target=hpc_cpu:Sub_Functions/IntegrationFext.py\n",
    "#%copy_data source=local:Sub_Functions/InternalEnergy.py target=hpc_cpu:Sub_Functions/InternalEnergy.py\n",
    "#%copy_data source=local:Sub_Functions/MultiLayerNet.py target=hpc_cpu:Sub_Functions/MultiLayerNet.py\n",
    "#%copy_data source=local:Sub_Functions/MultiLayerNet_Ray.py target=hpc_cpu:Sub_Functions/MultiLayerNet_Ray.py\n",
    "#%copy_data source=local:Sub_Functions/MultiLayerNet2.py target=hpc_cpu:Sub_Functions/MultiLayerNet2.py\n",
    "#%copy_data source=local:Sub_Functions/stress_eval.py target=hpc_cpu:Sub_Functions/stress_eval.py\n",
    "#%copy_data source=local:Sub_Functions/Stress_plot.py target=hpc_cpu:Sub_Functions/Stress_plot.py\n",
    "\n",
    "\n",
    "%copy_data source=local:Sub_Functions target=hpc_gpu:Sub_Functions\n",
    "%copy_data source=local:best_params.npz target=hpc_gpu:best_params.npz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "from Sub_Functions.MultiLayerNet import *\n",
    "from Sub_Functions.InternalEnergy import *\n",
    "from Sub_Functions.IntegrationFext import *\n",
    "from torch.autograd import grad\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdb7894ce30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "npr.seed(2025)\n",
    "torch.manual_seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def load_best_model(model, filename):\n",
    "    model.load_state_dict(torch.load(filename, map_location=torch.device('cpu')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "#------------------------- Constant Network Parameters ----------------\n",
    "D_in = 2\n",
    "D_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- Structural Parameters ---------------------\n",
    "Length = 4\n",
    "Height = 1\n",
    "Depth = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- Boundary Conditions ------------------------\n",
    "known_left_ux = 0\n",
    "known_left_uy = 0\n",
    "bc_left_penalty = 1.0\n",
    "\n",
    "known_right_tx = 0\n",
    "known_right_ty = -10\n",
    "bc_right_penalty = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- Material Parameters -----------------------\n",
    "model_energy = 'Elastic2D'\n",
    "E = 1000\n",
    "nu = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- Datapoints for training ---------------------\n",
    "Nx = 100\n",
    "Ny = 25\n",
    "x_min, y_min = (0.0, 0.0)\n",
    "hx = Length / (Nx - 1)\n",
    "hy = Height / (Ny - 1)\n",
    "shape = [Nx, Ny]\n",
    "dxdy = [hx, hy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- Datapoints for evaluation -----------------\n",
    "Length_test = 4\n",
    "Height_test = 1\n",
    "num_test_x = 201\n",
    "num_test_y = 100\n",
    "hx_test = Length / (num_test_x - 1)\n",
    "hy_test = Height / (num_test_y - 1)\n",
    "shape_test = [num_test_x, num_test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "CUDA not available, running on CPU\n",
      "cell finished on hpc_cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available, running on GPU\")\n",
    "    dev = torch.device('cuda')\n",
    "    device_string = 'cuda'\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "else:\n",
    "    device_string = 'cpu'\n",
    "    print(\"CUDA not available, running on CPU\")\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def get_Train_domain():\n",
    "    x_dom = x_min, Length, Nx\n",
    "    y_dom = y_min, Height, Ny\n",
    "    lin_x = np.linspace(x_dom[0], x_dom[1], x_dom[2])\n",
    "    lin_y = np.linspace(y_dom[0], y_dom[1], y_dom[2])\n",
    "    dom = np.zeros((Nx * Ny, 2))\n",
    "    c = 0\n",
    "    node_dy = (y_dom[1] - y_dom[0]) / (y_dom[2] - 1)\n",
    "    node_dx = (x_dom[1] - x_dom[0]) / (x_dom[2] - 1)\n",
    "    for x in np.nditer(lin_x):\n",
    "        tb = y_dom[2] * c\n",
    "        te = tb + y_dom[2]\n",
    "        c += 1\n",
    "        dom[tb:te, 0] = x\n",
    "        dom[tb:te, 1] = lin_y\n",
    "\n",
    "    bcl_u_pts_idx = np.where(dom[:, 0] == x_min)\n",
    "    bcl_u_pts = dom[bcl_u_pts_idx, :][0]\n",
    "    bcl_u = np.ones(np.shape(bcl_u_pts)) * [known_left_ux, known_left_uy]\n",
    "\n",
    "    bcr_t_pts_idx = np.where(dom[:, 0] == Length)\n",
    "    bcr_t_pts = dom[bcr_t_pts_idx, :][0]\n",
    "    bcr_t = np.ones(np.shape(bcr_t_pts)) * [known_right_tx, known_right_ty]\n",
    "\n",
    "    boundary_neumann = {\n",
    "        \"neumann_1\": {\n",
    "            \"coord\": bcr_t_pts,\n",
    "            \"known_value\": bcr_t,\n",
    "            \"penalty\": bc_right_penalty,\n",
    "            \"idx\": np.asarray(bcr_t_pts_idx)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    boundary_dirichlet = {\n",
    "        \"dirichlet_1\": {\n",
    "            \"coord\": bcl_u_pts,\n",
    "            \"known_value\": bcl_u,\n",
    "            \"penalty\": bc_left_penalty,\n",
    "            \"idx\": np.asarray(bcl_u_pts_idx)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    bcr_t_pts_idx_new = np.where((dom[:, 0] == Length) & (dom[:, 1] > 0.75))\n",
    "    bcr_t_pts_new = dom[bcr_t_pts_idx_new, :][0]\n",
    "    bcr_t_new = np.ones(np.shape(bcr_t_pts_new)) * [known_right_tx, known_right_ty]\n",
    "\n",
    "    boundary_neumann_new = {\n",
    "        \"neumann_1\": {\n",
    "            \"coord\": bcr_t_pts_new,\n",
    "            \"known_value\": bcr_t_new,\n",
    "            \"penalty\": bc_right_penalty,\n",
    "            \"idx\": np.asarray(bcr_t_pts_idx_new)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    dom = torch.from_numpy(dom).float()  # Cast to float\n",
    "\n",
    "    return dom, boundary_neumann, boundary_dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def get_Test_datatest(Nx=num_test_x, Ny=num_test_y):\n",
    "    x_dom_test = x_min, Length_test, Nx\n",
    "    y_dom_test = y_min, Height_test, Ny\n",
    "    x_space = np.linspace(x_dom_test[0], x_dom_test[1], x_dom_test[2])\n",
    "    y_space = np.linspace(y_dom_test[0], y_dom_test[1], y_dom_test[2])\n",
    "    xGrid, yGrid = np.meshgrid(x_space, y_space)\n",
    "    data_test = np.concatenate(\n",
    "        (np.array([xGrid.flatten()]).T, np.array([yGrid.flatten()]).T), axis=1)\n",
    "    return x_space, y_space, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def get_density():\n",
    "    density = torch.ones(Ny-1, Nx-1)\n",
    "    train_x_coord = np.transpose(dom[:, 0].reshape(Nx, Ny))\n",
    "    train_y_coord = np.transpose(dom[:, 1].reshape(Nx, Ny))\n",
    "\n",
    "    Crcl_x = Length / 2\n",
    "    Crcl_y = Height / 2\n",
    "    E_major = 0.25\n",
    "    E_minor = 0.25\n",
    "\n",
    "    for nodex in range(Nx):\n",
    "        for nodey in range(Ny):\n",
    "            if (((train_x_coord[nodey, nodex] - Crcl_x) / E_major) ** 2 + ((train_y_coord[nodey, nodex] - Crcl_y) / E_minor) ** 2 < 1):\n",
    "                density[nodey, nodex] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "class DeepEnergyMethod:\n",
    "    def __init__(self, model, dim, E, nu, act_func, CNN_dev, rff_dev, N_Layers):\n",
    "        self.model = MultiLayerNet(model[0], model[1], model[2], act_func, CNN_dev, rff_dev, N_Layers)\n",
    "        self.model = self.model.to(dev)\n",
    "        self.InternalEnergy = InternalEnergy(E, nu)\n",
    "        self.FextLoss = IntegrationFext(dim)\n",
    "        self.dim = dim\n",
    "        self.lossArray = []\n",
    "\n",
    "    def train_model(self, shape, dxdydz, data, neumannBC, dirichletBC, iteration, learning_rate, N_Layers, activatn_fn, density):\n",
    "        x = data.double().to(dev)  # Ensure data is double\n",
    "        x.requires_grad_(True)\n",
    "\n",
    "        dirBC_coordinates = {}\n",
    "        dirBC_values = {}\n",
    "        dirBC_penalty = {}\n",
    "        for i, keyi in enumerate(dirichletBC):\n",
    "            dirBC_coordinates[i] = torch.from_numpy(dirichletBC[keyi]['coord']).double().to(dev)\n",
    "            dirBC_values[i] = torch.from_numpy(dirichletBC[keyi]['known_value']).double().to(dev)\n",
    "            dirBC_penalty[i] = torch.tensor(dirichletBC[keyi]['penalty']).double().to(dev)\n",
    "\n",
    "        neuBC_coordinates = {}\n",
    "        neuBC_values = {}\n",
    "        neuBC_penalty = {}\n",
    "        neuBC_idx = {}\n",
    "        for i, keyi in enumerate(neumannBC):\n",
    "            neuBC_coordinates[i] = torch.from_numpy(neumannBC[keyi]['coord']).double().to(dev)\n",
    "            neuBC_coordinates[i].requires_grad_(True)\n",
    "            neuBC_values[i] = torch.from_numpy(neumannBC[keyi]['known_value']).double().to(dev)\n",
    "            neuBC_penalty[i] = torch.tensor(neumannBC[keyi]['penalty']).double().to(dev)\n",
    "            neuBC_idx[i] = torch.from_numpy(neumannBC[keyi]['idx']).double().to(dev)\n",
    "\n",
    "        optimizer_LBFGS = torch.optim.LBFGS(self.model.parameters(), lr=learning_rate, max_iter=20, line_search_fn='strong_wolfe')\n",
    "        start_time = time.time()\n",
    "        loss_history = np.zeros(iteration)\n",
    "\n",
    "        for t in range(iteration):\n",
    "            def closure():\n",
    "                u_pred = self.getU(x, N_Layers, activatn_fn)\n",
    "                storedEnergy = self.InternalEnergy.Elastic2DGauusQuad(u_pred, x, dxdydz, shape, density)\n",
    "                externalE = self.FextLoss.lossFextEnergy(u_pred, x, neuBC_coordinates, neuBC_values, neuBC_idx, dxdydz)\n",
    "                energy_loss = storedEnergy - externalE\n",
    "\n",
    "                bc_u_crit = torch.zeros((len(dirBC_coordinates)))\n",
    "                for i, vali in enumerate(dirBC_coordinates):\n",
    "                    dir_u_pred = self.getU(dirBC_coordinates[i], N_Layers, activatn_fn)\n",
    "                    bc_u_crit[i] = self.loss_squared_sum(dir_u_pred, dirBC_values[i])\n",
    "\n",
    "                boundary_loss = torch.sum(bc_u_crit)\n",
    "                loss = energy_loss + boundary_loss\n",
    "                optimizer_LBFGS.zero_grad()\n",
    "                loss.backward()\n",
    "                loss_history[t] = loss.item()\n",
    "                self.lossArray.append(loss.data)\n",
    "                return loss\n",
    "\n",
    "            if t > 0 and (np.abs(loss_history[t - 1] - loss_history[t - 2]) < 10e-5):\n",
    "                break\n",
    "\n",
    "            optimizer_LBFGS.step(closure)\n",
    "        elapsed = time.time() - start_time\n",
    "        return loss_history[:t]\n",
    "\n",
    "    def getU(self, x, N_Layers, activatn_fn):\n",
    "        u = self.model(x.double(), N_Layers, activatn_fn).double()  # Ensure x is double\n",
    "        Ux = x[:, 0] * u[:, 0]\n",
    "        Uy = x[:, 0] * u[:, 1]\n",
    "        Ux = Ux.reshape(Ux.shape[0], 1)\n",
    "        Uy = Uy.reshape(Uy.shape[0], 1)\n",
    "        u_pred = torch.cat((Ux, Uy), -1)\n",
    "        return u_pred\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_squared_sum(tinput, target):\n",
    "        row, column = tinput.shape\n",
    "        loss = 0\n",
    "        for j in range(column):\n",
    "            loss += torch.sum((tinput[:, j] - target[:, j]) ** 2) / tinput[:, j].data.nelement()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def plot_comparison(Ux, Uy, shape_test, filename='comparison_plot'):\n",
    "    # Load Abaqus results\n",
    "    abaqus_res = pd.read_excel(\"/Users/abueidd2/Library/CloudStorage/Box-Box/Optimizing_hyperparameters_and_architecture_of_deep_energy_method/Cybershuttle/Abaqus_Displacements.xlsx\", sheet_name=\"Bending\")\n",
    "    \n",
    "    # Verify the shape of the Abaqus results\n",
    "    print(abaqus_res.shape)\n",
    "\n",
    "    # Adjust the shape parameters based on the actual data\n",
    "    shape_ab = [201, 100]  # Adjust this based on actual data dimensions\n",
    "\n",
    "    x_coords_ab = abaqus_res.X_orignal.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "    y_coords_ab = abaqus_res.Y_orignal.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "\n",
    "    Ux_ab = abaqus_res.U1.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "    Uy_ab = abaqus_res.U2.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "\n",
    "    Ux_ab = np.where(Ux_ab == 0, 10**(-8), Ux_ab)\n",
    "    Uy_ab = np.where(Uy_ab == 0, 10**(-8), Uy_ab)\n",
    "\n",
    "    x_new_coords_ab = abaqus_res.X_disp.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "    y_new_coords_ab = abaqus_res.Y_disp.to_numpy().reshape(shape_ab[1], shape_ab[0])\n",
    "\n",
    "    error_Ux = abs(Ux.reshape(shape_test[1], shape_test[0]) - Ux_ab)\n",
    "    error_Uy = abs(Uy.reshape(shape_test[1], shape_test[0]) - Uy_ab)\n",
    "\n",
    "    L2_Ux = np.power(error_Ux, 2)\n",
    "    L2_Uy = np.power(error_Uy, 2)\n",
    "\n",
    "    L2_norm = np.sqrt(sum(sum((L2_Ux + L2_Uy))) / (shape_ab[1] * shape_ab[0]))\n",
    "    print('L2_norm= %0.8f' % (L2_norm))\n",
    "\n",
    "    #----------------- Final Plot-------------------\n",
    "    colorbar_ratio = 1\n",
    "    fig, ax = plt.subplots(3, 2)\n",
    "    fig.tight_layout()\n",
    "    plt.setp(ax, xticks=[0, 1, 2, 3, 4], yticks=[0, 1])\n",
    "\n",
    "    cp = ax[0][0].contourf(x_new_coords_ab.reshape(shape_test[1], shape_test[0]), y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                           Ux.reshape(shape_test[1], shape_test[0]), 12, cmap='jet')\n",
    "    ax[0][0].set_title('DEM: $U_x$')\n",
    "    ax[0][0].set_aspect('equal')\n",
    "    fig.colorbar(cp, shrink=colorbar_ratio, location='left', ax=ax[0][0])\n",
    "\n",
    "    cp2 = ax[0][1].contourf(x_new_coords_ab.reshape(shape_test[1], shape_test[0]), y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                            Uy.reshape(shape_test[1], shape_test[0]), 12, cmap='jet')\n",
    "    ax[0][1].set_title('DEM: $U_y$')\n",
    "    ax[0][1].set_aspect('equal')\n",
    "    fig.colorbar(cp2, shrink=colorbar_ratio, location='left', ax=ax[0][1])\n",
    "\n",
    "    cp = ax[1][0].contourf(x_new_coords_ab, y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                           Ux_ab.reshape(shape_test[1], shape_test[0]), 12, cmap='jet')\n",
    "    ax[1][0].set_title('FEM: $U_x$')\n",
    "    fig.colorbar(cp, shrink=colorbar_ratio, location='left', ax=ax[1][0])\n",
    "    ax[1][0].set_aspect('equal')\n",
    "\n",
    "    cp2 = ax[1][1].contourf(x_new_coords_ab.reshape(shape_test[1], shape_test[0]), y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                            Uy_ab.reshape(shape_test[1], shape_test[0]), 12, cmap='jet')\n",
    "    ax[1][1].set_aspect('equal')\n",
    "    ax[1][1].set_title('FEM: $U_y$')\n",
    "    fig.colorbar(cp2, shrink=colorbar_ratio, location='left', ax=ax[1][1])\n",
    "\n",
    "    cp = ax[2][0].contourf(x_new_coords_ab.reshape(shape_test[1], shape_test[0]), y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                           error_Ux, 12, cmap='jet')\n",
    "    ax[2][0].set_title('$Error_x$ = |$U_{x(FEA)}$ - $U_{x(DEM)}$|', y=1.08)\n",
    "    ax[2][0].set_aspect('equal')\n",
    "    fig.colorbar(cp, shrink=colorbar_ratio, location='left', ax=ax[2][0])\n",
    "\n",
    "    cp2 = ax[2][1].contourf(x_new_coords_ab.reshape(shape_test[1], shape_test[0]), y_new_coords_ab.reshape(shape_test[1], shape_test[0]),\n",
    "                            error_Uy, 12, cmap='jet')\n",
    "    ax[2][1].set_title('$Error_y$ = |$U_{y(FEA)}$ - $U_{y(DEM)}$|', y=1.08)\n",
    "    ax[2][1].set_aspect('equal')\n",
    "    fig.colorbar(cp2, shrink=colorbar_ratio, location='left', ax=ax[2][1])\n",
    "\n",
    "    fig.dpi = 700\n",
    "    fig.set_size_inches(6, 6)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the best hyperparameters\n",
    "    best_params = np.load('./best_params.npz', allow_pickle=True)\n",
    "    \n",
    "    lr = best_params['lr'].item()\n",
    "    neuron = best_params['neuron'].item()\n",
    "    CNN_dev = best_params['CNN_dev'].item()\n",
    "    rff_dev = best_params['rff_dev'].item()\n",
    "    N_Layers = best_params['N_Layers'].item()\n",
    "    act_func = best_params['act_func'].item()\n",
    "\n",
    "    dom, boundary_neumann, boundary_dirichlet = get_Train_domain()\n",
    "    x, y, datatest = get_Test_datatest()\n",
    "    density = 1\n",
    "\n",
    "    dem = DeepEnergyMethod([D_in, neuron, D_out], 2, E, nu, act_func, CNN_dev, rff_dev, N_Layers)\n",
    "    \n",
    "    # Load the best model\n",
    "    dem.model = load_best_model(dem.model, 'best_model.pth')\n",
    "\n",
    "    print('Loaded model with parameters:')\n",
    "    print('lr: %.10e\\t neuron: %.3d\\t CNN_Sdev: %.10e\\t RNN_Sdev: %.10e\\t Layers: %d\\t Act_fn: %s'\n",
    "          % (lr, neuron, CNN_dev, rff_dev, N_Layers, act_func))\n",
    "\n",
    "    # Load the loss history\n",
    "    loss_history = np.load('best_loss_history.npy')\n",
    "\n",
    "    # Plot the loss function\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(loss_history)), loss_history, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Function Convergence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Obtain displacements from the model\n",
    "    u_pred = dem.getU(torch.from_numpy(datatest).float().to(dev), N_Layers, act_func)\n",
    "    Ux = u_pred[:, 0].cpu().detach().numpy()\n",
    "    Uy = u_pred[:, 1].cpu().detach().numpy()\n",
    "\n",
    "    # Plot comparison with ground truth\n",
    "    plot_comparison(Ux, Uy, shape_test, filename='best_model_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m dem \u001b[38;5;241m=\u001b[39m DeepEnergyMethod([D_in, neuron, D_out], \u001b[38;5;241m2\u001b[39m, E, nu, act_func, CNN_dev, rff_dev, N_Layers)\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n",
      "\u001b[0;32m---> 19\u001b[0m dem\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded model with parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m neuron: \u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m CNN_Sdev: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m RNN_Sdev: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Layers: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Act_fn: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;32m     23\u001b[0m       \u001b[38;5;241m%\u001b[39m (lr, neuron, CNN_dev, rff_dev, N_Layers, act_func))\n",
      "\n",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m, in \u001b[0;36mload_best_model\u001b[0;34m(model, filename)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_best_model\u001b[39m(model, filename):\n",
      "\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n",
      "\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n",
      "\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n",
      "\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n",
      "\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n",
      "\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n",
      "\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n",
      "\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n",
      "\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n",
      "\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n",
      "\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pth'\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m dem \u001b[38;5;241m=\u001b[39m DeepEnergyMethod([D_in, neuron, D_out], \u001b[38;5;241m2\u001b[39m, E, nu, act_func, CNN_dev, rff_dev, N_Layers)\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n",
      "\u001b[0;32m---> 19\u001b[0m dem\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded model with parameters:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m neuron: \u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m CNN_Sdev: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m RNN_Sdev: \u001b[39m\u001b[38;5;132;01m%.10e\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Layers: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Act_fn: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;32m     23\u001b[0m       \u001b[38;5;241m%\u001b[39m (lr, neuron, CNN_dev, rff_dev, N_Layers, act_func))\n",
      "\n",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m, in \u001b[0;36mload_best_model\u001b[0;34m(model, filename)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_best_model\u001b[39m(model, filename):\n",
      "\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n",
      "\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n",
      "\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n",
      "\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n",
      "\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n",
      "\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n",
      "\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n",
      "\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n",
      "\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n",
      "\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\n",
      "File \u001b[0;32m/dev/shm/scratch/envs/b7a017a2/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n",
      "\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pth'\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_cpu...\n",
      "waiting for cell to finish on hpc_cpu...\n",
      "A259341095            \u001b[0m\u001b[01;34mSub_Functions\u001b[0m/   best_params.npz           kernel.py\n",
      "AiravataAgent.stderr  \u001b[01;32mairavata-agent\u001b[0m*  connection_2cysym0u.json  \u001b[01;32mmicromamba\u001b[0m*\n",
      "AiravataAgent.stdout  \u001b[01;36mapplication\u001b[0m@     job_324730075.slurm\n",
      "cell finished on hpc_cpu.\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
